{
    "_target_": "rwd_llm.chains.EvidenceChain.from_openai_llm",
    "preamble": "\nYou are an AI assistant trained to answer questions based on source documents. If you\nare unsure of the correct answer, you should answer \"Unsure\", but provide the relevant\nevidence text to the \"Unsure\" decision.\n",
    "question": "Is the patient experiencing abdominal pain",
    "llm_class": {"_target_": "hydra.utils.get_class", "path": "langchain_openai.AzureOpenAI"},
    "llm_extra_args": { "model_name": "text-davinci-003", "deployment_name": "text-davinci-003"},
    "answer_mapping": ["met", "not met", "Unsure"],
    "examples": [
        {
            "_target_": rwd_llm.chains.evidence_chain_prompts.EvidenceChainExample,
            "text": "The patient arrived at the hospital complaining of chest pain. The\n patient loves the color blue.  She was released after observation",
            "answer": "blue",
            "evidence": "The\n patient loves the color blue."
        },
        {
            "_target_": rwd_llm.chains.evidence_chain_prompts.EvidenceChainExample,
            "text": "The patient has a familiy history of breast cancer. Her intake paperwork\n indicates that she likes the color purple. She was released after\n observation",
            "answer": "purple",
            "evidence": "Her intake paperwork\n indicates that she likes the color purple."
        }
    ],
}
