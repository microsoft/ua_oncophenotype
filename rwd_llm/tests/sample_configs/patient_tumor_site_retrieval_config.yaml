defaults:
  - config/experiment/dataset@dataset: onco_dataset_small
  # - config/experiment/dataset@dataset: sample_patient_dataset
  - config/experiment/chain: patient_retrieval_chain

# some options for the experiment

# model_name: "gpt-4"
# model_name: "text-davinci-003"
# deployment_name: ${model_name}
# deployment_name: ${model_name}
model_name: gpt-3.5-turbo
deployment_name: gpt-35-turbo

azure_openai:
  class:
    _target_: "hydra.utils.get_class"
    path: "langchain.chat_models.AzureChatOpenAI"
  extra_args:
    deployment_name: ${deployment_name}
    model_name: ${model_name}

openai:
  class:
    _target_: "hydra.utils.get_class"
    path: "langchain.chat_models.ChatOpenAI"
  extra_args:
    model_name: ${model_name}

# choose the llm to use
llm: ${azure_openai}

# the actual config
config:
  _target_: rwd_llm.experiment_config.ExperimentConfig
  resources: 
    - "dataset": ${dataset}
  experiment:
    _target_: rwd_llm.experiment.Experiment
    dataset:
      _target_: rwd_llm.experiment_config.ComponentRegistry.get
      name: "dataset"
    chain:
      note_types:
        - PathologyReport
      classifier:
        # override some values from the chain specified in defults
        _target_: rwd_llm.chains.ChatEvidenceChain.from_openai_llm
        llm_class: ${llm.class}
        llm_extra_args: ${llm.extra_args}
        question: "What is the primary tumor site?"
        answer_mapping: ["Lung", "Breast", "Pancreas", "Prostate", "Unsure"]
        examples: []
    data_runner:
      _target_: rwd_llm.experiment.data_runners.DatasetRunner
      n_threads: 1
    evaluation:
      _target_: rwd_llm.eval.ClassificationEvaluation
  output_dir: "experiment_output"
